"""
Semantic Extractor - Executes semantic patterns without LLM or exec()

This replaces brittle CSS selector code with resilient semantic strategies.
"""

import re
import logging
from typing import List, Dict, Any, Optional
from bs4 import BeautifulSoup, Tag

logger = logging.getLogger(__name__)


class SemanticExtractor:
    """
    Execute semantic extraction patterns on HTML.
    
    This is deterministic and requires NO LLM calls - it interprets
    semantic patterns generated by the AI and applies them to HTML.
    
    Key Difference from Current Approach:
    - Current: Executes Python code with CSS selectors (brittle)
    - Semantic: Interprets strategy patterns (resilient)
    """
    
    def __init__(self):
        """Initialize semantic extractor."""
        self.strategy_handlers = {
            'heading': self._extract_heading,
            'bold_text': self._extract_bold_text,
            'link_text': self._extract_link_text,
            'attribute': self._extract_attribute,
            'currency': self._extract_currency,
            'number': self._extract_number,
            'date': self._extract_date,
            'image': self._extract_image,
            'text_contains': self._extract_text_contains,
            'css_selector': self._extract_css_selector,  # Fallback to CSS if needed
            'xpath': self._extract_xpath,  # Fallback to XPath if needed
            'first_text': self._extract_first_text,
            'semantic_element': self._extract_semantic_element,
        }
        logger.info(" Semantic Extractor initialized")
    
    def extract(
        self,
        html: str,
        semantic_pattern: Dict[str, Any],
        containers: Optional[List[Tag]] = None
    ) -> List[Dict[str, Any]]:
        """
        Extract data using semantic patterns.
        
        Args:
            html: Raw HTML string
            semantic_pattern: Semantic extraction pattern (from AI)
            containers: Pre-detected repeating containers (from DOMPatternDetector)
            
        Returns:
            List of extracted items
            
        Example semantic_pattern:
        {
            "title": {
                "primary": {"type": "heading", "position": "first"},
                "fallbacks": [
                    {"type": "bold_text", "min_length": 20},
                    {"type": "link_text"}
                ]
            },
            "price": {
                "primary": {"type": "currency"},
                "fallbacks": [
                    {"type": "attribute", "name": "data-price"},
                    {"type": "text_contains", "pattern": r"\$\d+"}
                ]
            }
        }
        """
        soup = BeautifulSoup(html, 'html.parser')
        
        # If containers not provided, use entire document
        if containers is None:
            containers = [soup]
        
        logger.info(f" Extracting from {len(containers)} container(s) using semantic patterns")
        
        results = []
        for i, container in enumerate(containers):
            item = {}
            
            for field_name, field_pattern in semantic_pattern.items():
                # Try primary strategy
                value = self._execute_strategy(container, field_pattern.get('primary', {}))
                
                # Try fallbacks if primary fails
                if value is None or value == '':
                    fallbacks = field_pattern.get('fallbacks', [])
                    for fallback in fallbacks:
                        value = self._execute_strategy(container, fallback)
                        if value is not None and value != '':
                            logger.debug(f"    Field '{field_name}' extracted via fallback: {fallback.get('type')}")
                            break
                
                # Validate if validation rules provided
                validation = field_pattern.get('validation', {})
                if validation and value:
                    value = self._validate_value(value, validation)
                
                item[field_name] = value
            
            # Only add items that have at least some data
            if any(v is not None and v != '' for v in item.values()):
                results.append(item)
        
        logger.info(f" Extracted {len(results)} items using semantic patterns")
        return results
    
    def _execute_strategy(self, element: Tag, strategy: Dict[str, Any]) -> Optional[str]:
        """
        Execute a single semantic strategy.
        
        Args:
            element: BeautifulSoup element (container or document)
            strategy: Strategy dict with 'type' and optional parameters
            
        Returns:
            Extracted value or None
        """
        if not strategy or not isinstance(strategy, dict):
            return None
        
        strategy_type = strategy.get('type')
        if not strategy_type:
            return None
        
        handler = self.strategy_handlers.get(strategy_type)
        if not handler:
            logger.warning(f" Unknown strategy type: {strategy_type}")
            return None
        
        try:
            return handler(element, strategy)
        except Exception as e:
            logger.debug(f"   Strategy {strategy_type} failed: {e}")
            return None
    
    # ========== Strategy Handlers ==========
    
    def _extract_heading(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract heading text (h1-h6)."""
        position = strategy.get('position', 'first')
        tags = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']
        
        if position == 'first':
            for tag in tags:
                heading = element.find(tag)
                if heading:
                    return heading.get_text(strip=True)
        elif position == 'last':
            for tag in reversed(tags):
                heading = element.find(tag)
                if heading:
                    return heading.get_text(strip=True)
        
        return None
    
    def _extract_bold_text(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract bold text (strong, b tags)."""
        min_length = strategy.get('min_length', 0)
        
        for tag in ['strong', 'b']:
            bold = element.find(tag)
            if bold:
                text = bold.get_text(strip=True)
                if len(text) >= min_length:
                    return text
        
        return None
    
    def _extract_link_text(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract link text or href."""
        return_type = strategy.get('return', 'text')  # 'text' or 'href'
        position = strategy.get('position', 'first')
        
        links = element.find_all('a')
        if not links:
            return None
        
        link = links[0] if position == 'first' else links[-1]
        
        if return_type == 'href':
            return link.get('href')
        else:
            return link.get_text(strip=True)
    
    def _extract_attribute(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract attribute value (data-*, aria-*, etc)."""
        attr_name = strategy.get('name')
        if not attr_name:
            return None
        
        # Try direct attribute
        if element.has_attr(attr_name):
            return element[attr_name]
        
        # Try finding element with attribute
        elem_with_attr = element.find(attrs={attr_name: True})
        if elem_with_attr:
            return elem_with_attr[attr_name]
        
        return None
    
    def _extract_currency(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract currency value (text with $, €, £, etc)."""
        currency_symbols = strategy.get('symbols', ['$', '€', '£', '¥', '₹'])
        
        # Search all text in element
        for text in element.stripped_strings:
            for symbol in currency_symbols:
                if symbol in text:
                    # Try to extract just the numeric part
                    match = re.search(r'[\d,]+\.?\d*', text)
                    if match:
                        return text  # Return full text with symbol
        
        return None
    
    def _extract_number(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract numeric value."""
        pattern = strategy.get('pattern', r'\d+')
        
        for text in element.stripped_strings:
            match = re.search(pattern, text)
            if match:
                return match.group(0)
        
        return None
    
    def _extract_date(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract date from <time> tag or text."""
        # Try <time> tag first
        time_tag = element.find('time')
        if time_tag:
            # Prefer datetime attribute
            if time_tag.has_attr('datetime'):
                return time_tag['datetime']
            return time_tag.get_text(strip=True)
        
        # Try common date patterns
        date_patterns = [
            r'\d{4}-\d{2}-\d{2}',  # YYYY-MM-DD
            r'\d{2}/\d{2}/\d{4}',  # MM/DD/YYYY
            r'\w+ \d{1,2}, \d{4}',  # Month DD, YYYY
        ]
        
        for text in element.stripped_strings:
            for pattern in date_patterns:
                match = re.search(pattern, text)
                if match:
                    return match.group(0)
        
        return None
    
    def _extract_image(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract image src."""
        return_type = strategy.get('return', 'src')  # 'src' or 'alt'
        
        img = element.find('img')
        if img:
            if return_type == 'alt':
                return img.get('alt', '')
            return img.get('src', img.get('data-src', ''))
        
        return None
    
    def _extract_text_contains(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract text matching a pattern."""
        pattern = strategy.get('pattern')
        if not pattern:
            return None
        
        for text in element.stripped_strings:
            if re.search(pattern, text):
                return text
        
        return None
    
    def _extract_css_selector(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Fallback: Use CSS selector if provided."""
        selector = strategy.get('selector')
        if not selector:
            return None
        
        found = element.select_one(selector)
        if found:
            return found.get_text(strip=True)
        
        return None
    
    def _extract_xpath(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Fallback: Use XPath if provided (requires lxml)."""
        # Note: BeautifulSoup doesn't natively support XPath
        # This would require lxml integration
        logger.warning(" XPath extraction not yet implemented")
        return None
    
    def _extract_first_text(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract first non-empty text."""
        min_length = strategy.get('min_length', 0)
        
        for text in element.stripped_strings:
            if len(text) >= min_length:
                return text
        
        return None
    
    def _extract_semantic_element(self, element: Tag, strategy: Dict) -> Optional[str]:
        """Extract from semantic HTML5 elements (article, section, etc)."""
        tag_name = strategy.get('tag', 'article')
        
        semantic_elem = element.find(tag_name)
        if semantic_elem:
            return semantic_elem.get_text(strip=True)
        
        return None
    
    # ========== Validation ==========
    
    def _validate_value(self, value: str, validation: Dict) -> Optional[str]:
        """
        Validate extracted value against rules.
        
        Validation rules:
        - not_empty: bool
        - min_length: int
        - max_length: int
        - pattern: regex
        - type: 'number', 'email', 'url', etc
        """
        if not value:
            return None if validation.get('not_empty') else value
        
        # Min length
        min_len = validation.get('min_length')
        if min_len and len(value) < min_len:
            return None
        
        # Max length
        max_len = validation.get('max_length')
        if max_len and len(value) > max_len:
            value = value[:max_len]
        
        # Pattern matching
        pattern = validation.get('pattern')
        if pattern and not re.search(pattern, value):
            return None
        
        # Type validation
        val_type = validation.get('type')
        if val_type == 'number' and not re.search(r'\d', value):
            return None
        elif val_type == 'email' and '@' not in value:
            return None
        elif val_type == 'url' and not value.startswith(('http://', 'https://', '/')):
            return None
        
        return value





